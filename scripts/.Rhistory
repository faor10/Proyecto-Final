regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes del modelo en funci?n de la regularizaci?n") +
theme_bw() +
theme(legend.position = "none")
cv_error_ridge <- cv.glmnet(
x      = x_train,
y      = y_train,
alpha  = 0,
nfolds = 10,
type.measure = "mse",
standardize  = T
)
plot(cv_error_ridge)
paste("Mejor valor de lambda encontrado:", cv_error_ridge$lambda.min)
paste("Mejor valor de lambda encontrado + 1 desviaci?n est?ndar:", cv_error_ridge$lambda.1se)
cv_error_ridge ##Lambda min=0.06625, MSE=0.03141
modelo2_ridge_lambdamin <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
lambda      = cv_error_ridge$lambda.min,
standardize = TRUE
)
modelo2_ridge_lambdamin
df_coeficientes_ridge <- coef(modelo2_ridge_lambdamin) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
##Coeficientes modelo ridge
df_coeficientes_ridge
##GrÃ¡fica importancia coeficientes ridge
df_coeficientes_ridge %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y = coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge") +
theme_bw() +
theme(axis.text.x = element_text(size = 6, angle = 45))
##Predicciones en test
x.test <- model.matrix( ~ pobl_tot + areaoficialkm2 + discapital + vrf_peq_productor + lights_mean, testR)[, -1]
predict_test_ridge <- predict(modelo2_ridge_lambdamin, newx = x.test)
predict_test_ridge
# Create a dataframe of all x and predicted SL responses
predictions_finales <- data.frame(testR, predict_test_ridge)
predictions_finales<-rename(predictions_finales, ln_pib_prediccion =s0)
predictions_finales<-rename(predictions_finales, year =ano)
testR<-rename(testR, year =ano)
predictions_finales<-predictions_finales%>% mutate(pib=exp(ln_pib_prediccion))
View(predictions_finales)
x_train <- model.matrix( ~ pobl_tot  + discapital  + vrf_peq_productor + lights_mean, data = trainR)[, -1]
y_train <- trainR$ln_pib
#scale(x_train)
model2_ridge <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
nlambda     = 100,
standardize = T
)
regularizacion <- model2_ridge$beta %>%
as.matrix() %>%
t() %>%
as_tibble() %>%
mutate(lambda = model2_ridge$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes del modelo en funci?n de la regularizaci?n") +
theme_bw() +
theme(legend.position = "none")
cv_error_ridge <- cv.glmnet(
x      = x_train,
y      = y_train,
alpha  = 0,
nfolds = 10,
type.measure = "mse",
standardize  = T
)
plot(cv_error_ridge)
paste("Mejor valor de lambda encontrado:", cv_error_ridge$lambda.min)
paste("Mejor valor de lambda encontrado + 1 desviaci?n est?ndar:", cv_error_ridge$lambda.1se)
cv_error_ridge ##Lambda min=0.06625, MSE=0.03141
modelo2_ridge_lambdamin <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
lambda      = cv_error_ridge$lambda.min,
standardize = TRUE
)
modelo2_ridge_lambdamin
df_coeficientes_ridge <- coef(modelo2_ridge_lambdamin) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
##Coeficientes modelo ridge
df_coeficientes_ridge
##GrÃ¡fica importancia coeficientes ridge
df_coeficientes_ridge %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y = coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge") +
theme_bw() +
theme(axis.text.x = element_text(size = 6, angle = 45))
##Predicciones en test
x.test <- model.matrix( ~ pobl_tot + areaoficialkm2 + discapital + vrf_peq_productor + lights_mean, testR)[, -1]
predict_test_ridge <- predict(modelo2_ridge_lambdamin, newx = x.test)
##Predicciones en test
x.test <- model.matrix( ~ pobl_tot  + discapital + vrf_peq_productor + lights_mean, testR)[, -1]
predict_test_ridge <- predict(modelo2_ridge_lambdamin, newx = x.test)
predict_test_ridge
View(predictions_finales)
x_train <- model.matrix( ~ pobl_tot  + discapital  + g_cap + vrf_peq_productor + lights_mean, data = trainR)[, -1]
y_train <- trainR$ln_pib
#scale(x_train)
model2_ridge <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
nlambda     = 100,
standardize = T
)
regularizacion <- model2_ridge$beta %>%
as.matrix() %>%
t() %>%
as_tibble() %>%
mutate(lambda = model2_ridge$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes del modelo en funci?n de la regularizaci?n") +
theme_bw() +
theme(legend.position = "none")
cv_error_ridge <- cv.glmnet(
x      = x_train,
y      = y_train,
alpha  = 0,
nfolds = 10,
type.measure = "mse",
standardize  = T
)
plot(cv_error_ridge)
paste("Mejor valor de lambda encontrado:", cv_error_ridge$lambda.min)
paste("Mejor valor de lambda encontrado + 1 desviaci?n est?ndar:", cv_error_ridge$lambda.1se)
cv_error_ridge ##Lambda min=0.06625, MSE=0.03141
modelo2_ridge_lambdamin <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
lambda      = cv_error_ridge$lambda.min,
standardize = TRUE
)
modelo2_ridge_lambdamin
df_coeficientes_ridge <- coef(modelo2_ridge_lambdamin) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
##Coeficientes modelo ridge
df_coeficientes_ridge
##GrÃ¡fica importancia coeficientes ridge
df_coeficientes_ridge %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y = coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge") +
theme_bw() +
theme(axis.text.x = element_text(size = 6, angle = 45))
##Predicciones en test
x.test <- model.matrix( ~ pobl_tot  + g_cap +discapital + vrf_peq_productor + lights_mean, testR)[, -1]
predict_test_ridge <- predict(modelo2_ridge_lambdamin, newx = x.test)
predict_test_ridge
# Create a dataframe of all x and predicted SL responses
predictions_finales <- data.frame(testR, predict_test_ridge)
predictions_finales<-rename(predictions_finales, ln_pib_prediccion =s0)
predictions_finales<-rename(predictions_finales, year =ano)
testR<-rename(testR, year =ano)
predictions_finales<-predictions_finales%>% mutate(pib=exp(ln_pib_prediccion))
View(predictions_finales)
x_train <- model.matrix( ~ pobl_tot  + discapital  + lights_mean, data = trainR)[, -1]
y_train <- trainR$ln_pib
#scale(x_train)
model2_ridge <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
nlambda     = 100,
standardize = T
)
regularizacion <- model2_ridge$beta %>%
as.matrix() %>%
t() %>%
as_tibble() %>%
mutate(lambda = model2_ridge$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes del modelo en funci?n de la regularizaci?n") +
theme_bw() +
theme(legend.position = "none")
cv_error_ridge <- cv.glmnet(
x      = x_train,
y      = y_train,
alpha  = 0,
nfolds = 10,
type.measure = "mse",
standardize  = T
)
plot(cv_error_ridge)
paste("Mejor valor de lambda encontrado:", cv_error_ridge$lambda.min)
paste("Mejor valor de lambda encontrado + 1 desviaci?n est?ndar:", cv_error_ridge$lambda.1se)
cv_error_ridge ##Lambda min=0.06625, MSE=0.03141
modelo2_ridge_lambdamin <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
lambda      = cv_error_ridge$lambda.min,
standardize = TRUE
)
modelo2_ridge_lambdamin
df_coeficientes_ridge <- coef(modelo2_ridge_lambdamin) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
##Coeficientes modelo ridge
df_coeficientes_ridge
##GrÃ¡fica importancia coeficientes ridge
df_coeficientes_ridge %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y = coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge") +
theme_bw() +
theme(axis.text.x = element_text(size = 6, angle = 45))
##Predicciones en test
x.test <- model.matrix( ~ pobl_tot  + discapital  + lights_mean, testR)[, -1]
predict_test_ridge <- predict(modelo2_ridge_lambdamin, newx = x.test)
predict_test_ridge
# Create a dataframe of all x and predicted SL responses
predictions_finales <- data.frame(testR, predict_test_ridge)
predictions_finales<-rename(predictions_finales, ln_pib_prediccion =s0)
predictions_finales<-rename(predictions_finales, year =ano)
testR<-rename(testR, year =ano)
predictions_finales<-predictions_finales%>% mutate(pib=exp(ln_pib_prediccion))
View(predictions_finales)
View(predictions_finales)
#Modelo 2 Ridge****************************************
'%ni%' <- Negate("%in%")
trainR<-subset(trainR,depto %ni% c('Bogotá, D.C.'))
x_train <- model.matrix( ~ pobl_tot  + discapital  + vrf_peq_productor + lights_mean, data = trainR)[, -1]
y_train <- trainR$ln_pib
#scale(x_train)
model2_ridge <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
nlambda     = 100,
standardize = T
)
regularizacion <- model2_ridge$beta %>%
as.matrix() %>%
t() %>%
as_tibble() %>%
mutate(lambda = model2_ridge$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes del modelo en funci?n de la regularizaci?n") +
theme_bw() +
theme(legend.position = "none")
cv_error_ridge <- cv.glmnet(
x      = x_train,
y      = y_train,
alpha  = 0,
nfolds = 10,
type.measure = "mse",
standardize  = T
)
plot(cv_error_ridge)
paste("Mejor valor de lambda encontrado:", cv_error_ridge$lambda.min)
paste("Mejor valor de lambda encontrado + 1 desviaci?n est?ndar:", cv_error_ridge$lambda.1se)
cv_error_ridge ##Lambda min=0.06625, MSE=0.03141
modelo2_ridge_lambdamin <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
lambda      = cv_error_ridge$lambda.min,
standardize = TRUE
)
modelo2_ridge_lambdamin
df_coeficientes_ridge <- coef(modelo2_ridge_lambdamin) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
##Coeficientes modelo ridge
df_coeficientes_ridge
##GrÃ¡fica importancia coeficientes ridge
df_coeficientes_ridge %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y = coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge") +
theme_bw() +
theme(axis.text.x = element_text(size = 6, angle = 45))
'%ni%' <- Negate("%in%")
testR<-subset(testR,depto %ni% c('Bogotá, D.C.'))
x.test <- model.matrix( ~ pobl_tot  + discapital  + lights_mean, testR)[, -1]
predict_test_ridge <- predict(modelo2_ridge_lambdamin, newx = x.test)
x.test <- model.matrix( ~  pobl_tot  + discapital  + vrf_peq_productor + lights_mean, testR)[, -1]
predict_test_ridge <- predict(modelo2_ridge_lambdamin, newx = x.test)
predict_test_ridge
# Create a dataframe of all x and predicted SL responses
predictions_finales <- data.frame(testR, predict_test_ridge)
predictions_finales<-rename(predictions_finales, ln_pib_prediccion =s0)
predictions_finales<-rename(predictions_finales, year =ano)
testR<-rename(testR, year =ano)
predictions_finales<-predictions_finales%>% mutate(pib=exp(ln_pib_prediccion))
View(predictions_finales)
final2 %>%
ggplot( aes(x=year, y=pib_sum, group=depto, color=depto)) +
geom_line() +
scale_color_viridis(discrete = TRUE) +
ggtitle("PIB por Depto") +
ylab("PIB")
final<-predictions_finales %>%
group_by(depto, year) %>%
summarize(pib_sum = sum(pib))
final2<-subset(final,depto %ni% c('Bogotá, D.C.'))
final2 %>%
ggplot( aes(x=year, y=pib_sum, group=depto, color=depto)) +
geom_line() +
scale_color_viridis(discrete = TRUE) +
ggtitle("PIB por Depto") +
ylab("PIB")
rm(list=ls())
require(pacman)
p_load(here , tidyverse, haven, gtsummary, caret,ggplot2,dplyr,viridis)
path = here('')
train <- read_dta(here(path,"stores/train.dta"))
test <- read_dta(here(path,"stores/test.dta"))
saveRDS(train,paste0(path,"/stores/trainR.rds"))
saveRDS(test,paste0(path,"/stores/testR.rds"))
## Llama/instala-llama las librer?as listadas
p_load(tidyverse,rio,
sf, # Leer/escribir/manipular datos espaciales
leaflet, # Visualizaciones din?micas
tmaptools, # geocode_OSM()
osmdata,
spdep,
secr,
osmdata,
here) # Get OSM's data
path = here('')
##Librerias requeridas
rm(list=ls())
require("pacman")
p_load("here")
p_load("readr")
p_load(ggplot2) # Librer?a para visualizar datos
p_load(scales) # Formato de los ejes en las gr?ficas
p_load(ggpubr) # Combinar gr?ficas
p_load(rio) # Librer?a para importar datos
p_load(tidyverse) # Librer?a para limpiar datos
p_load(e1071) # Tiene la funci?n para calcular skewness
p_load(EnvStats) # Transformaci?n Box-Cox
p_load(tidymodels) # Modelos ML
p_load(ggplot2) # Librer?a para visualizar datos
p_load(scales) # Formato de los ejes en las gr?ficas
p_load(ggpubr) # Combinar gr?ficas
p_load(knitr) # Tablas dentro de Rmarkdown
p_load(kableExtra) # Tablas dentro de Rmarkdown
p_load(dplyr)
p_load(caret)
p_load(glmnet)
p_load(pls)
p_load(tidyr)
p_load(tibble)
p_load(gtsummary)
testR <- readRDS("D:/OneDrive - Universidad de los Andes/Intersemestral 2/Big Data/Trabajo Final/GitHub/Proyecto-Final/stores/testR.rds")
trainR <- readRDS("D:/OneDrive - Universidad de los Andes/Intersemestral 2/Big Data/Trabajo Final/GitHub/Proyecto-Final/stores/trainR.rds")
#Creamos log del pib
train<- train%>% mutate(ln_pib=log(pib_cons))
#Creamos log del pib
trainR<- trainR%>% mutate(ln_pib=log(pib_cons))
mod1 <- lm(ln_pib ~ pobl_tot + areaoficialkm2 + y_total +discapital + g_cap + finan_credito + vrf_peq_productor + lights_mean , data = trainR)
summary(mod1)
x_train <- model.matrix( ~ pobl_tot + areaoficialkm2 + y_total +discapital  + vrf_peq_productor + lights_mean, data = trainR)[, -1]
y_train <- trainR$ln_pib
#scale(x_train)
model2_ridge <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
nlambda     = 100,
standardize = T
)
regularizacion <- model2_ridge$beta %>%
as.matrix() %>%
t() %>%
as_tibble() %>%
mutate(lambda = model2_ridge$lambda)
regularizacion <- regularizacion %>%
pivot_longer(
cols = !lambda,
names_to = "predictor",
values_to = "coeficientes"
)
regularizacion %>%
ggplot(aes(x = lambda, y = coeficientes, color = predictor)) +
geom_line() +
scale_x_log10(
breaks = trans_breaks("log10", function(x) 10^x),
labels = trans_format("log10", math_format(10^.x))
) +
labs(title = "Coeficientes del modelo en funci?n de la regularizaci?n") +
theme_bw() +
theme(legend.position = "none")
cv_error_ridge <- cv.glmnet(
x      = x_train,
y      = y_train,
alpha  = 0,
nfolds = 10,
type.measure = "mse",
standardize  = T
)
plot(cv_error_ridge)
paste("Mejor valor de lambda encontrado:", cv_error_ridge$lambda.min)
paste("Mejor valor de lambda encontrado + 1 desviaci?n est?ndar:", cv_error_ridge$lambda.1se)
cv_error_ridge ##Lambda min=0.06625, MSE=0.03141
modelo2_ridge_lambdamin <- glmnet(
x           = x_train,
y           = y_train,
alpha       = 0,
lambda      = cv_error_ridge$lambda.min,
standardize = TRUE
)
modelo2_ridge_lambdamin
df_coeficientes_ridge <- coef(modelo2_ridge_lambdamin) %>%
as.matrix() %>%
as_tibble(rownames = "predictor") %>%
rename(coeficiente = s0)
##Coeficientes modelo ridge
df_coeficientes_ridge
##GrÃ¡fica importancia coeficientes ridge
df_coeficientes_ridge %>%
filter(predictor != "(Intercept)") %>%
ggplot(aes(x = predictor, y = coeficiente)) +
geom_col() +
labs(title = "Coeficientes del modelo Ridge") +
theme_bw() +
theme(axis.text.x = element_text(size = 6, angle = 45))
##Predicciones en test
x.test <- model.matrix( ~ pobl_tot + areaoficialkm2 + discapital  + vrf_peq_productor + lights_mean, testR)[, -1]
##Predicciones en test
x.test <- model.matrix( ~ pobl_tot + areaoficialkm2 + y_total +discapital + g_cap + finan_credito + vrf_peq_productor + lights_mean, testR)[, -1]
predict_test_ridge <- predict(modelo2_ridge_lambdamin, newx = x.test)
##Predicciones en test
x.test <- model.matrix( ~ pobl_tot + areaoficialkm2 + y_total +discapital  + vrf_peq_productor + lights_mean, testR)[, -1]
predict_test_ridge <- predict(modelo2_ridge_lambdamin, newx = x.test)
predict_test_ridge
# Create a dataframe of all x and predicted SL responses
predictions_finales <- data.frame(testR, predict_test_ridge)
predictions_finales<-rename(predictions_finales, ln_pib_prediccion =s0)
predictions_finales<-rename(predictions_finales, year =ano)
testR<-rename(testR, year =ano)
predictions_finales<-predictions_finales%>% mutate(pib=exp(ln_pib_prediccion))
View(predictions_finales)
